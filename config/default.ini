[training]
iteration = 300
training_batch = 2
testing_batch = 1

[batch-norm]
scale = 1
offset = 0
variance_epsilon = 0.001
decay = 0.999

[init]
mean = 1
std = 0.046875
relu_clip = 100

[forward-net]
num_cep = 264
n_hidden_1 = 128
n_hidden_2 = 128
n_hidden_3 = 256
n_hidden_5 = 128

[bi-rnn]
n_hidden_4 = 128
forget_bias = 1

[classification-net]
n_hidden_6 = 25

[adam]
beta1 = 0.9
beta2 = 0.999
epsilon = 1e-8
learning_rate = 0.001